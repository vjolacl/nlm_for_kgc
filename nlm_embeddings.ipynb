{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d67582-315c-4dc7-8b9b-37e8dcb6ffbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:25:05.303002: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 12:25:05.445825: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-15 12:25:06.326357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/bwhpc/common/devel/cuda/11.8/lib64\n",
      "2023-03-15 12:25:06.326439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/bwhpc/common/devel/cuda/11.8/lib64\n",
      "2023-03-15 12:25:06.326446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a023f3af-93af-4e85-bdfe-86436f723e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263dc0ca-c95a-49ff-8364-e8ea9fb3339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e960c56d-5b97-43d9-a52d-0b89e5e8c0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>definition</th>\n",
       "      <th>entity</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14854262</td>\n",
       "      <td>stool, solid excretory product evacuated from ...</td>\n",
       "      <td>stool</td>\n",
       "      <td>solid excretory product evacuated from the bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>590383</td>\n",
       "      <td>chieftainship, the position of chieftain</td>\n",
       "      <td>chieftainship</td>\n",
       "      <td>the position of chieftain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8769179</td>\n",
       "      <td>saxony, an area in Germany around the upper El...</td>\n",
       "      <td>saxony</td>\n",
       "      <td>an area in Germany around the upper Elbe rive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2338145</td>\n",
       "      <td>ondatra zibethica, beaver-like aquatic rodent ...</td>\n",
       "      <td>ondatra zibethica</td>\n",
       "      <td>beaver-like aquatic rodent of North America w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990168</td>\n",
       "      <td>founder, sink below the surface</td>\n",
       "      <td>founder</td>\n",
       "      <td>sink below the surface</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                         definition  \\\n",
       "0  14854262  stool, solid excretory product evacuated from ...   \n",
       "1    590383           chieftainship, the position of chieftain   \n",
       "2   8769179  saxony, an area in Germany around the upper El...   \n",
       "3   2338145  ondatra zibethica, beaver-like aquatic rodent ...   \n",
       "4   1990168                    founder, sink below the surface   \n",
       "\n",
       "              entity                                        description  \n",
       "0              stool   solid excretory product evacuated from the bo...  \n",
       "1      chieftainship                          the position of chieftain  \n",
       "2             saxony   an area in Germany around the upper Elbe rive...  \n",
       "3  ondatra zibethica   beaver-like aquatic rodent of North America w...  \n",
       "4            founder                             sink below the surface  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entity2text = pd.read_csv('data/wn18rr_entity2text.txt', delimiter=\"\\t\", header = None, names=[\"id\", \"definition\"])\n",
    "df_entity2text[[\"entity\", \"description\"]] = df_entity2text[\"definition\"].str.split(',', n=1, expand=True)\n",
    "df_entity2text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb40e128-1421-4f50-a670-de76a65dbc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the KG entities\n",
    "input_to_tokens = tokenizer(df_entity2text[\"entity\"].to_list(), padding=True, return_tensors='pt')['input_ids']\n",
    "input_to_tokens.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105367f6-8443-497c-8ce6-f3e33714e7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = customdata(input_to_tokens)\n",
    "dataloader = torch.utils.data.DataLoader(cd, batch_size = 2500, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de6b307-02f6-4578-aac9-3b5bd5e8d053",
   "metadata": {},
   "source": [
    "#### Generate BERT embeddings in batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90f854a-de7a-425e-af01-583edfcb7c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Usage in Iteration: 1 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 2 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 3 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 4 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 5 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 6 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 7 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 8 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 9 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 10 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 11 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 12 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 13 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 14 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 15 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 16 | Allocated: 27.8 GB | Cached:  28.2 GB\n",
      "Memory Usage in Iteration: 17 | Allocated: 10.7 GB | Cached:  11.0 GB\n"
     ]
    }
   ],
   "source": [
    "iter = 1\n",
    "embeddings = []\n",
    "for data in dataloader:\n",
    "    data = data.to(\"cuda:0\")\n",
    "    output = generate_bert_embeddings(data,model)\n",
    "    output = torch.stack(output, 0)# output is originally tuple â†’ stack BERT hidden layers (13) tensors into 1 tensor    \n",
    "\n",
    "    if iter < 10:\n",
    "        batch_nr = \"0\" + str(iter)\n",
    "    else:\n",
    "        batch_nr = str(iter)\n",
    "    #torch.save(output, \"nlm_embeddings/bert_wn18rr/\" + batch_nr + \"_bert_4lastlayers_wn18rr_ent.pt\")\n",
    "    #embeddings.append(output)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Additional Info when using cuda\n",
    "    print('Memory Usage in Iteration:', iter,\n",
    "          '| Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB |', \n",
    "          'Cached: ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "    \n",
    "    iter = iter + 1\n",
    "    del data\n",
    "    del output\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928201db-34f1-4819-a6cd-f5c9e1f902a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ec68a5-a210-4666-bb4b-a40d9c922ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Allocated: 0.4 GB | Cached:  0.5 GB\n"
     ]
    }
   ],
   "source": [
    "print('| Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB |', \n",
    "          'Cached: ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6245c6e4-a6d7-43cf-ab3c-2e8307c25cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(embeddings,'/nlm_embeddings/bert_wn18rr/bert_4lastlayers_wn18rr_ent.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlm_kge",
   "language": "python",
   "name": "nlm_kge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
